{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING MARTIN'S CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_combined_data(base_path):\n",
    "#     data = []\n",
    "#     for i in range(1, 5):  # Loop through each of the combined_data files\n",
    "#         file_path = os.path.join(base_path, f'combined_data_{i}.txt')\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             movie_id = None\n",
    "#             for line in file:\n",
    "#                 line = line.strip()\n",
    "#                 if line.endswith(\":\"):\n",
    "#                     movie_id = int(line[:-1])\n",
    "#                 else:\n",
    "#                     customer_id, rating, date = line.split(\",\")\n",
    "#                     data.append([movie_id, int(customer_id), int(rating), date])\n",
    "\n",
    "#     df_sub = pd.DataFrame(data, columns=[\"MovieID\", \"CustomerID\", \"Rating\", \"Date\"])\n",
    "#     return df_sub\n",
    "\n",
    "def load_combined_data(base_path):\n",
    "    data = []\n",
    "    with open(base_path, 'r') as file:\n",
    "        movie_id = None\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.endswith(\":\"):\n",
    "                movie_id = int(line[:-1])\n",
    "            else:\n",
    "                customer_id, rating, date = line.split(\",\")\n",
    "                data.append([movie_id, int(customer_id), int(rating), date])\n",
    "\n",
    "    df_sub = pd.DataFrame(data, columns=[\"MovieID\", \"CustomerID\", \"Rating\", \"Date\"])\n",
    "    return df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the base directory path from the user\n",
    "base_path = '/Users/Ryan/Desktop/BT4222/combined_data_1.txt/combined_data_1.txt'\n",
    "\n",
    "# Load the data and create the DataFrame\n",
    "df = load_combined_data(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "\n",
    "# print(type(df['Date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MovieID  CustomerID  rating     timestamp\n",
      "0        1     1488844       3  1.125965e+09\n",
      "1        1      822109       5  1.115942e+09\n",
      "2        1      885013       4  1.129680e+09\n",
      "3        1       30878       4  1.135555e+09\n",
      "4        1      823519       3  1.083542e+09\n"
     ]
    }
   ],
   "source": [
    "#Converting date into timestamp\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert 'Date' to timestamp and rename rating column\n",
    "df['timestamp'] = pd.to_datetime(df['Date']).apply(lambda x: x.timestamp())\n",
    "df = df.rename(columns={'Rating': 'rating'})\n",
    "\n",
    "# Drop the original 'Date' column\n",
    "df = df.drop(columns=['Date'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['timestamp'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial user_id\n",
      "   CustomerID\n",
      "0     1488844\n",
      "1      822109\n",
      "2      885013\n",
      "3       30878\n",
      "4      823519\n",
      "final user_id\n",
      "   CustomerID  userId\n",
      "0     1488844       0\n",
      "1      822109       1\n",
      "2      885013       2\n",
      "3       30878       3\n",
      "4      823519       4\n",
      "initial df \n",
      "   MovieID  CustomerID  rating     timestamp  userId\n",
      "0        1     1488844       3  1.125965e+09       0\n",
      "1        1      822109       5  1.115942e+09       1\n",
      "2        1      885013       4  1.129680e+09       2\n",
      "3        1       30878       4  1.135555e+09       3\n",
      "4        1      823519       3  1.083542e+09       4\n",
      "initial item_id\n",
      "      MovieID\n",
      "0           1\n",
      "547         2\n",
      "692         3\n",
      "2704        4\n",
      "2846        5\n",
      "final item_id\n",
      "      MovieID  itemId\n",
      "0           1       0\n",
      "547         2       1\n",
      "692         3       2\n",
      "2704        4       3\n",
      "2846        5       4\n",
      "final df \n",
      "   MovieID  CustomerID  rating     timestamp  userId  itemId\n",
      "0        1     1488844       3  1.125965e+09       0       0\n",
      "1        1      822109       5  1.115942e+09       1       0\n",
      "2        1      885013       4  1.129680e+09       2       0\n",
      "3        1       30878       4  1.135555e+09       3       0\n",
      "4        1      823519       3  1.083542e+09       4       0\n",
      "final final df \n",
      "   userId  itemId  rating     timestamp\n",
      "0       0       0       3  1.125965e+09\n",
      "1       1       0       5  1.115942e+09\n",
      "2       2       0       4  1.129680e+09\n",
      "3       3       0       4  1.135555e+09\n",
      "4       4       0       3  1.083542e+09\n",
      "Range of userId is [0, 470757]\n",
      "Range of itemId is [0, 4498]\n"
     ]
    }
   ],
   "source": [
    "user_id = df[['CustomerID']].drop_duplicates().reindex()\n",
    "\n",
    "print(\"initial user_id\")\n",
    "print(user_id.head())\n",
    "\n",
    "user_id['userId'] = np.arange(len(user_id)) \n",
    "\n",
    "print(\"final user_id\")\n",
    "print(user_id.head())\n",
    "\n",
    "df = pd.merge(df, user_id, on=['CustomerID'], how='left')\n",
    "\n",
    "print(\"initial df \")\n",
    "print(df.head())\n",
    "\n",
    "item_id = df[['MovieID']].drop_duplicates()\n",
    "\n",
    "print(\"initial item_id\")\n",
    "print(item_id.head())\n",
    "\n",
    "item_id['itemId'] = np.arange(len(item_id))\n",
    "\n",
    "print(\"final item_id\")\n",
    "print(item_id.head())\n",
    "\n",
    "df = pd.merge(df, item_id, on=['MovieID'], how='left')\n",
    "\n",
    "print(\"final df \")\n",
    "print(df.head())\n",
    "\n",
    "df = df[['userId', 'itemId', 'rating', 'timestamp']]\n",
    "\n",
    "print(\"final final df \")\n",
    "print(df.head())\n",
    "\n",
    "print('Range of userId is [{}, {}]'.format(df.userId.min(), df.userId.max()))\n",
    "print('Range of itemId is [{}, {}]'.format(df.itemId.min(), df.itemId.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sampled = df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# print(df_sampled.head())\n",
    "\n",
    "# print('Range of userId is [{}, {}]'.format(df_sampled.userId.min(), df_sampled.userId.max()))\n",
    "# print('Range of itemId is [{}, {}]'.format(df_sampled.itemId.min(), df_sampled.itemId.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of userId is [0, 7999]\n",
      "Range of itemId is [0, 4498]\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your original DataFrame with a 'user_id' column\n",
    "# Replace 'n' with the desired number of unique user_ids to keep\n",
    "desired_unique_users = 8000\n",
    "\n",
    "# Get a subset of user_ids to keep\n",
    "subset_user_ids = df['userId'].unique()[:desired_unique_users]\n",
    "\n",
    "# Filter the DataFrame to keep only rows with user_ids in the subset\n",
    "df_reduced = df[df['userId'].isin(subset_user_ids)]\n",
    "\n",
    "print('Range of userId is [{}, {}]'.format(df_reduced.userId.min(), df_reduced.userId.max()))\n",
    "print('Range of itemId is [{}, {}]'.format(df_reduced.itemId.min(), df_reduced.itemId.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24053764\n",
      "1152161\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(df_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gmf import GMFEngine\n",
    "from mlp import MLPEngine\n",
    "from neumf import NeuMFEngine\n",
    "from data import SampleGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_config = {'alias': 'gmf_factor8neg4-implict',\n",
    "              'num_epoch': 1,\n",
    "              'batch_size': 1024,\n",
    "              # 'optimizer': 'sgd',\n",
    "              # 'sgd_lr': 1e-3,\n",
    "              # 'sgd_momentum': 0.9,\n",
    "              # 'optimizer': 'rmsprop',\n",
    "              # 'rmsprop_lr': 1e-3,\n",
    "              # 'rmsprop_alpha': 0.99,\n",
    "              # 'rmsprop_momentum': 0,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 7985,\n",
    "              'num_items': 4498,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'l2_regularization': 0, # 0.01\n",
    "              'use_cuda': False,\n",
    "              'device_id': 0,\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_config = {'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 256,  # 1024,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'layers': [16,64,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "              'l2_regularization': 0.0000001,  # MLP model is sensitive to hyper params\n",
    "              'use_cuda': False,\n",
    "              'device_id': 7,\n",
    "              'pretrain': True,\n",
    "              'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 200,\n",
    "                'batch_size': 1024,\n",
    "                'optimizer': 'adam',\n",
    "                'adam_lr': 1e-3,\n",
    "                'num_users': 6040,\n",
    "                'num_items': 3706,\n",
    "                'latent_dim_mf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'num_negative': 4,\n",
    "                'layers': [16,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'l2_regularization': 0.01,\n",
    "                'use_cuda': False,\n",
    "                'device_id': 7,\n",
    "                'pretrain': True,\n",
    "                'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "                'pretrain_mlp': 'checkpoints/{}'.format('mlp_factor8neg4_Epoch100_HR0.5606_NDCG0.2463.model'),\n",
    "                'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "ml1m_dir = 'data/ml-1m/ratings.dat'\n",
    "ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ml1m_rating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ml1m_rating['timestamp'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Create a sample DataFrame\n",
    "# data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "# df = pd.DataFrame(data, index=['row1', 'row2', 'row3'])\n",
    "\n",
    "# print(\"Original DataFrame:\")\n",
    "# print(df)\n",
    "\n",
    "# # Reindex the DataFrame with a new set of indices\n",
    "# new_index = ['row1', 'row2', 'row3', 'row4']\n",
    "# df_reindexed = df.reindex(new_index)\n",
    "\n",
    "# print(\"\\nDataFrame after reindexing:\")\n",
    "# print(df_reindexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex\n",
    "\n",
    "##Actually why is there a need to reindex?\n",
    "\n",
    "user_id = ml1m_rating[['uid']].drop_duplicates().reindex()\n",
    "\n",
    "print(\"initial user_id\")\n",
    "print(user_id.head())\n",
    "\n",
    "user_id['userId'] = np.arange(len(user_id)) \n",
    "\n",
    "print(\"final user_id\")\n",
    "print(user_id.head())\n",
    "\n",
    "ml1m_rating = pd.merge(ml1m_rating, user_id, on=['uid'], how='left')\n",
    "\n",
    "print(\"initial ml1m_rating \")\n",
    "print(ml1m_rating.head())\n",
    "\n",
    "item_id = ml1m_rating[['mid']].drop_duplicates()\n",
    "\n",
    "print(\"initial user_id\")\n",
    "print(item_id.head())\n",
    "\n",
    "item_id['itemId'] = np.arange(len(item_id))\n",
    "\n",
    "print(\"final user_id\")\n",
    "print(item_id.head())\n",
    "\n",
    "ml1m_rating = pd.merge(ml1m_rating, item_id, on=['mid'], how='left')\n",
    "\n",
    "print(\"final ml1m_rating \")\n",
    "print(ml1m_rating.head())\n",
    "\n",
    "ml1m_rating = ml1m_rating[['userId', 'itemId', 'rating', 'timestamp']]\n",
    "\n",
    "print(\"final final ml1m_rating \")\n",
    "print(ml1m_rating.head())\n",
    "\n",
    "print('Range of userId is [{}, {}]'.format(ml1m_rating.userId.min(), ml1m_rating.userId.max()))\n",
    "print('Range of itemId is [{}, {}]'.format(ml1m_rating.itemId.min(), ml1m_rating.itemId.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ml1m_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ml1m_rating.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader for training\n",
    "sample_generator = SampleGenerator(ratings=ml1m_rating)\n",
    "evaluate_data = sample_generator.evaluate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ryan\\Desktop\\GitHub_public\\neural-collaborative-filtering\\src\\data.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings['rating'][ratings['rating'] > 0] = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7985\n",
      "4499\n",
      "----\n",
      "7985\n",
      "1836\n"
     ]
    }
   ],
   "source": [
    "# DataLoader for training (MARTIN'S code)\n",
    "sample_generator1 = SampleGenerator(ratings=df_reduced)\n",
    "evaluate_data1 = sample_generator1.evaluate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the exact model\n",
    "config = gmf_config\n",
    "engine = GMFEngine(config)\n",
    "# config = mlp_config\n",
    "# engine = MLPEngine(config)\n",
    "# config = neumf_config\n",
    "# engine = NeuMFEngine(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starts !\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ryan\\Desktop\\GitHub_public\\neural-collaborative-filtering\\src\\training_ryan.ipynb Cell 28\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ryan/Desktop/GitHub_public/neural-collaborative-filtering/src/training_ryan.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m80\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ryan/Desktop/GitHub_public/neural-collaborative-filtering/src/training_ryan.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_loader \u001b[39m=\u001b[39m sample_generator1\u001b[39m.\u001b[39minstance_a_train_loader(config[\u001b[39m'\u001b[39m\u001b[39mnum_negative\u001b[39m\u001b[39m'\u001b[39m], config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ryan/Desktop/GitHub_public/neural-collaborative-filtering/src/training_ryan.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m engine\u001b[39m.\u001b[39;49mtrain_an_epoch(train_loader, epoch_id\u001b[39m=\u001b[39;49mepoch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ryan/Desktop/GitHub_public/neural-collaborative-filtering/src/training_ryan.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m hit_ratio, ndcg \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39mevaluate(evaluate_data, epoch_id\u001b[39m=\u001b[39mepoch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ryan/Desktop/GitHub_public/neural-collaborative-filtering/src/training_ryan.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m engine\u001b[39m.\u001b[39msave(config[\u001b[39m'\u001b[39m\u001b[39malias\u001b[39m\u001b[39m'\u001b[39m], epoch, hit_ratio, ndcg)\n",
      "File \u001b[1;32mc:\\Users\\Ryan\\Desktop\\GitHub_public\\neural-collaborative-filtering\\src\\engine.py:46\u001b[0m, in \u001b[0;36mEngine.train_an_epoch\u001b[1;34m(self, train_loader, epoch_id)\u001b[0m\n\u001b[0;32m     44\u001b[0m user, item, rating \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m], batch[\u001b[39m1\u001b[39m], batch[\u001b[39m2\u001b[39m]\n\u001b[0;32m     45\u001b[0m rating \u001b[39m=\u001b[39m rating\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m---> 46\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_single_batch(user, item, rating)\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m[Training Epoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m] Batch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Loss \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch_id, batch_id, loss))\n\u001b[0;32m     48\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\Ryan\\Desktop\\GitHub_public\\neural-collaborative-filtering\\src\\engine.py:31\u001b[0m, in \u001b[0;36mEngine.train_single_batch\u001b[1;34m(self, users, items, ratings)\u001b[0m\n\u001b[0;32m     29\u001b[0m     users, items, ratings \u001b[39m=\u001b[39m users\u001b[39m.\u001b[39mcuda(), items\u001b[39m.\u001b[39mcuda(), ratings\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 31\u001b[0m ratings_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(users, items)\n\u001b[0;32m     32\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrit(ratings_pred\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), ratings)\n\u001b[0;32m     33\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Ryan\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Ryan\\Desktop\\GitHub_public\\neural-collaborative-filtering\\src\\gmf.py:21\u001b[0m, in \u001b[0;36mGMF.forward\u001b[1;34m(self, user_indices, item_indices)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, user_indices, item_indices):\n\u001b[0;32m     20\u001b[0m     user_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_user(user_indices)\n\u001b[1;32m---> 21\u001b[0m     item_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_item(item_indices)\n\u001b[0;32m     22\u001b[0m     element_product \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmul(user_embedding, item_embedding)\n\u001b[0;32m     23\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maffine_output(element_product)\n",
      "File \u001b[1;32mc:\\Users\\Ryan\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Ryan\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    159\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32mc:\\Users\\Ryan\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2193\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2194\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2195\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2199\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "for epoch in range(config['num_epoch']):\n",
    "    print('Epoch {} starts !'.format(epoch))\n",
    "    print('-' * 80)\n",
    "    train_loader = sample_generator1.instance_a_train_loader(config['num_negative'], config['batch_size'])\n",
    "    engine.train_an_epoch(train_loader, epoch_id=epoch)\n",
    "    hit_ratio, ndcg = engine.evaluate(evaluate_data, epoch_id=epoch)\n",
    "    engine.save(config['alias'], epoch, hit_ratio, ndcg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

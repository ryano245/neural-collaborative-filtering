{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gmf import GMFEngine\n",
    "from mlp import MLPEngine\n",
    "from neumf import NeuMFEngine\n",
    "from data import SampleGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MovieID  CustomerID  Rating        Date\n",
      "0        1     1488844       3  2005-09-06\n",
      "1        1      822109       5  2005-05-13\n",
      "2        1      885013       4  2005-10-19\n",
      "3        1       30878       4  2005-12-26\n",
      "4        1      823519       3  2004-05-03\n"
     ]
    }
   ],
   "source": [
    "# def load_combined_data(base_path):\n",
    "#     data = []\n",
    "#     for i in range(1, 5):  # Loop through each of the combined_data files\n",
    "#         file_path = os.path.join(base_path, f'combined_data_{i}.txt')\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             movie_id = None\n",
    "#             for line in file:\n",
    "#                 line = line.strip()\n",
    "#                 if line.endswith(\":\"):\n",
    "#                     movie_id = int(line[:-1])\n",
    "#                 else:\n",
    "#                     customer_id, rating, date = line.split(\",\")\n",
    "#                     data.append([movie_id, int(customer_id), int(rating), date])\n",
    "\n",
    "#     df_sub = pd.DataFrame(data, columns=[\"MovieID\", \"CustomerID\", \"Rating\", \"Date\"])\n",
    "#     return df_sub\n",
    "\n",
    "###CURRENTLY JUST USING 1 COMBINED DATASET\n",
    "\n",
    "def load_combined_data(base_path):\n",
    "    data = []\n",
    "    with open(base_path, 'r') as file:\n",
    "        movie_id = None\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.endswith(\":\"):\n",
    "                movie_id = int(line[:-1])\n",
    "            else:\n",
    "                customer_id, rating, date = line.split(\",\")\n",
    "                data.append([movie_id, int(customer_id), int(rating), date])\n",
    "\n",
    "    df_sub = pd.DataFrame(data, columns=[\"MovieID\", \"CustomerID\", \"Rating\", \"Date\"])\n",
    "    return df_sub\n",
    "\n",
    "\n",
    "# Get the base directory path from the user\n",
    "base_path = '/Users/Ryan/Desktop/BT4222/combined_data_1.txt/combined_data_1.txt'\n",
    "\n",
    "# Load the data and create the DataFrame\n",
    "df = load_combined_data(base_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MovieID  CustomerID  rating     timestamp\n",
      "0        1     1488844       3  1.125965e+09\n",
      "1        1      822109       5  1.115942e+09\n",
      "2        1      885013       4  1.129680e+09\n",
      "3        1       30878       4  1.135555e+09\n",
      "4        1      823519       3  1.083542e+09\n"
     ]
    }
   ],
   "source": [
    "#Converting date into timestamp\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert 'Date' to timestamp and rename rating column\n",
    "df['timestamp'] = pd.to_datetime(df['Date']).apply(lambda x: x.timestamp())\n",
    "df = df.rename(columns={'Rating': 'rating'})\n",
    "\n",
    "# Drop the original 'Date' column\n",
    "df = df.drop(columns=['Date'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# print(type(df['timestamp'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial user_id\n",
      "   CustomerID\n",
      "0     1488844\n",
      "1      822109\n",
      "2      885013\n",
      "3       30878\n",
      "4      823519\n",
      "final user_id\n",
      "   CustomerID  userId\n",
      "0     1488844       0\n",
      "1      822109       1\n",
      "2      885013       2\n",
      "3       30878       3\n",
      "4      823519       4\n",
      "initial df \n",
      "   MovieID  CustomerID  rating     timestamp  userId\n",
      "0        1     1488844       3  1.125965e+09       0\n",
      "1        1      822109       5  1.115942e+09       1\n",
      "2        1      885013       4  1.129680e+09       2\n",
      "3        1       30878       4  1.135555e+09       3\n",
      "4        1      823519       3  1.083542e+09       4\n",
      "initial item_id\n",
      "      MovieID\n",
      "0           1\n",
      "547         2\n",
      "692         3\n",
      "2704        4\n",
      "2846        5\n",
      "final item_id\n",
      "      MovieID  itemId\n",
      "0           1       0\n",
      "547         2       1\n",
      "692         3       2\n",
      "2704        4       3\n",
      "2846        5       4\n",
      "final df \n",
      "   MovieID  CustomerID  rating     timestamp  userId  itemId\n",
      "0        1     1488844       3  1.125965e+09       0       0\n",
      "1        1      822109       5  1.115942e+09       1       0\n",
      "2        1      885013       4  1.129680e+09       2       0\n",
      "3        1       30878       4  1.135555e+09       3       0\n",
      "4        1      823519       3  1.083542e+09       4       0\n",
      "final final df \n",
      "   userId  itemId  rating     timestamp\n",
      "0       0       0       3  1.125965e+09\n",
      "1       1       0       5  1.115942e+09\n",
      "2       2       0       4  1.129680e+09\n",
      "3       3       0       4  1.135555e+09\n",
      "4       4       0       3  1.083542e+09\n",
      "Range of userId is [0, 470757]\n",
      "Range of itemId is [0, 4498]\n"
     ]
    }
   ],
   "source": [
    "### CONVERTING [CustomerID -> userId, MovieID -> itemsId] to match format for data loader\n",
    "\n",
    "user_id = df[['CustomerID']].drop_duplicates().reindex()\n",
    "\n",
    "print(\"initial user_id\")\n",
    "print(user_id.head())\n",
    "\n",
    "user_id['userId'] = np.arange(len(user_id)) \n",
    "\n",
    "print(\"final user_id\")\n",
    "print(user_id.head())\n",
    "\n",
    "df = pd.merge(df, user_id, on=['CustomerID'], how='left')\n",
    "\n",
    "print(\"initial df \")\n",
    "print(df.head())\n",
    "\n",
    "item_id = df[['MovieID']].drop_duplicates()\n",
    "\n",
    "print(\"initial item_id\")\n",
    "print(item_id.head())\n",
    "\n",
    "item_id['itemId'] = np.arange(len(item_id))\n",
    "\n",
    "print(\"final item_id\")\n",
    "print(item_id.head())\n",
    "\n",
    "df = pd.merge(df, item_id, on=['MovieID'], how='left')\n",
    "\n",
    "print(\"final df \")\n",
    "print(df.head())\n",
    "\n",
    "df = df[['userId', 'itemId', 'rating', 'timestamp']]\n",
    "\n",
    "print(\"final final df \")\n",
    "print(df.head())\n",
    "\n",
    "print('Range of userId is [{}, {}]'.format(df.userId.min(), df.userId.max()))\n",
    "print('Range of itemId is [{}, {}]'.format(df.itemId.min(), df.itemId.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of userId is [0, 7999]\n",
      "Range of itemId is [0, 4498]\n"
     ]
    }
   ],
   "source": [
    "### DOWNSIZING DATA (original dataset too big - Memory Error)\n",
    "\n",
    "##Reduce by sampling a % of dataset\n",
    "# df_sampled = df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# print(df_sampled.head())\n",
    "\n",
    "# print('Range of userId is [{}, {}]'.format(df_sampled.userId.min(), df_sampled.userId.max()))\n",
    "# print('Range of itemId is [{}, {}]'.format(df_sampled.itemId.min(), df_sampled.itemId.max()))\n",
    "\n",
    "##Reduce by decreasing number of unique users\n",
    "desired_unique_users = 8000\n",
    "\n",
    "# Get a subset of user_ids to keep\n",
    "subset_user_ids = df['userId'].unique()[:desired_unique_users]\n",
    "\n",
    "# Filter the DataFrame to keep only rows with user_ids in the subset\n",
    "df_reduced = df[df['userId'].isin(subset_user_ids)]\n",
    "\n",
    "print('Range of userId is [{}, {}]'.format(df_reduced.userId.min(), df_reduced.userId.max()))\n",
    "print('Range of itemId is [{}, {}]'.format(df_reduced.itemId.min(), df_reduced.itemId.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24053764\n",
      "1152161\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "###Comparing the length of the dataset\n",
    "\n",
    "print(len(df))\n",
    "# print(len(df_sampled))\n",
    "print(len(df_reduced))\n",
    "\n",
    "rating_range = df_reduced['rating'].min(), df_reduced['rating'].max()\n",
    "\n",
    "print(rating_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_config = {'alias': 'gmf_factor8neg4-implict',\n",
    "              'num_epoch': 1,\n",
    "              'batch_size': 1024,\n",
    "              # 'optimizer': 'sgd',\n",
    "              # 'sgd_lr': 1e-3,\n",
    "              # 'sgd_momentum': 0.9,\n",
    "              # 'optimizer': 'rmsprop',\n",
    "              # 'rmsprop_lr': 1e-3,\n",
    "              # 'rmsprop_alpha': 0.99,\n",
    "              # 'rmsprop_momentum': 0,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 8000,\n",
    "              'num_items': 4499,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'l2_regularization': 0, # 0.01\n",
    "              'use_cuda': False,\n",
    "              'device_id': 0,\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_config = {'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 256,  # 1024,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'layers': [16,64,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "              'l2_regularization': 0.0000001,  # MLP model is sensitive to hyper params\n",
    "              'use_cuda': False,\n",
    "              'device_id': 7,\n",
    "              'pretrain': True,\n",
    "              'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 200,\n",
    "                'batch_size': 1024,\n",
    "                'optimizer': 'adam',\n",
    "                'adam_lr': 1e-3,\n",
    "                'num_users': 6040,\n",
    "                'num_items': 3706,\n",
    "                'latent_dim_mf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'num_negative': 4,\n",
    "                'layers': [16,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'l2_regularization': 0.01,\n",
    "                'use_cuda': False,\n",
    "                'device_id': 7,\n",
    "                'pretrain': True,\n",
    "                'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "                'pretrain_mlp': 'checkpoints/{}'.format('mlp_factor8neg4_Epoch100_HR0.5606_NDCG0.2463.model'),\n",
    "                'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ryan\\Desktop\\GitHub_public\\neural-collaborative-filtering\\src\\data.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings['rating'][ratings['rating'] > 0] = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2)    userId                                   interacted_items\n",
      "0       0  {0, 7, 4108, 16, 2068, 2071, 4122, 29, 4134, 4...\n",
      "1       1  {0, 1541, 1797, 1809, 2579, 3859, 1306, 2593, ...\n",
      "2       2  {0, 4097, 4, 2056, 1551, 4114, 1560, 3610, 413...\n",
      "3       3  {0, 2050, 4, 17, 2071, 4122, 27, 29, 4135, 43,...\n",
      "4       4  {0, 1026, 1541, 1542, 7, 3078, 1034, 2571, 16,...\n",
      "-------\n",
      "(8000, 3)    userId                                   interacted_items  \\\n",
      "0       0  {0, 7, 4108, 16, 2068, 2071, 4122, 29, 4134, 4...   \n",
      "1       1  {0, 1541, 1797, 1809, 2579, 3859, 1306, 2593, ...   \n",
      "2       2  {0, 4097, 4, 2056, 1551, 4114, 1560, 3610, 413...   \n",
      "3       3  {0, 2050, 4, 17, 2071, 4122, 27, 29, 4135, 43,...   \n",
      "4       4  {0, 1026, 1541, 1542, 7, 3078, 1034, 2571, 16,...   \n",
      "\n",
      "                                      negative_items  \n",
      "0  {1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
      "1  {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
      "2  {1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
      "3  {1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
      "4  {1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
      "--------\n",
      "(8000, 4)    userId                                   interacted_items  \\\n",
      "0       0  {0, 7, 4108, 16, 2068, 2071, 4122, 29, 4134, 4...   \n",
      "1       1  {0, 1541, 1797, 1809, 2579, 3859, 1306, 2593, ...   \n",
      "2       2  {0, 4097, 4, 2056, 1551, 4114, 1560, 3610, 413...   \n",
      "3       3  {0, 2050, 4, 17, 2071, 4122, 27, 29, 4135, 43,...   \n",
      "4       4  {0, 1026, 1541, 1542, 7, 3078, 1034, 2571, 16,...   \n",
      "\n",
      "                                      negative_items  \\\n",
      "0  {1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
      "1  {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "2  {1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
      "3  {1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
      "4  {1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
      "\n",
      "                                    negative_samples  \n",
      "0  [3913, 1782, 3509, 4126, 1950, 181, 1194, 4479...  \n",
      "1  [1802, 4166, 1146, 2327, 1150, 779, 2069, 4396...  \n",
      "2  [3698, 4356, 2185, 528, 118, 785, 3334, 11, 41...  \n",
      "3  [2807, 4467, 4300, 963, 2644, 2554, 1100, 2915...  \n",
      "4  [2219, 4043, 593, 771, 1114, 1278, 332, 687, 3...  \n",
      "7985\n",
      "4499\n",
      "----\n",
      "7985\n",
      "1836\n"
     ]
    }
   ],
   "source": [
    "# DataLoader for training\n",
    "sample_generator1 = SampleGenerator(ratings=df_reduced)\n",
    "evaluate_data1 = sample_generator1.evaluate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the exact model\n",
    "config = gmf_config\n",
    "engine = GMFEngine(config)\n",
    "# config = mlp_config\n",
    "# engine = MLPEngine(config)\n",
    "# config = neumf_config\n",
    "# engine = NeuMFEngine(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ryan\\Desktop\\GitHub_public\\neural-collaborative-filtering\\src\\martin_data_gmf.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ryan/Desktop/GitHub_public/neural-collaborative-filtering/src/martin_data_gmf.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config[\u001b[39m'\u001b[39m\u001b[39mnum_epoch\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ryan/Desktop/GitHub_public/neural-collaborative-filtering/src/martin_data_gmf.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m starts !\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ryan/Desktop/GitHub_public/neural-collaborative-filtering/src/martin_data_gmf.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m80\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(config['num_epoch']):\n",
    "    print('Epoch {} starts !'.format(epoch))\n",
    "    print('-' * 80)\n",
    "    train_loader = sample_generator1.instance_a_train_loader(config['num_negative'], config['batch_size'])\n",
    "    engine.train_an_epoch(train_loader, epoch_id=epoch)\n",
    "    hit_ratio, ndcg = engine.evaluate(evaluate_data1, epoch_id=epoch)\n",
    "    engine.save(config['alias'], epoch, hit_ratio, ndcg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
